---
layout: post
comments: true
title: Regression and ANOVA
---

Anova에 대하여 전반적으로 포스팅을 하도록 하겠습니다. 회귀해석에 대한 사전지식이 필요합니다. Anova를 더 쉽게 이해하기 위해, 다음과 같은 순서로 포스팅하고자 합니다.

< 목차 >
1. F-test
2. Regression
3. Regression and test
4. Anova


## 1. F test

(1) 언제 F test를 사용하는가?

F test는 검정통계량이 귀무가설 하에 F분포를 따를 때 수행할 수 있는 모든 통계적 test를 말합니다. 주로 우리는 F test를 **comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled**(출처:wiki) , 다시 말해 모집단으로 부터 샘플링된 데이터셋을 설명하는 데 가장 적합한 통계적 모델을 선별하는 데 사용되는 test입니다. 이 때, fitted 된 모델들은 *least squares* 방법을 써서 만들어진다고 합니다.

(2) F statistic의 examples - f test of the equality of two variances

Fisher은 처음 1920년에 F 검정통계량을 두 분산의 ratio로써 정의내렸습니다. 이에서 유추할 수 있듯이, f test를 사용하는 가장 common한 상황은 아래와 같이 나눌 수 있습니다.

* 두 집단 간 분산이 동일한지 test
* Lack-of-fit sum of squares : 제안된 회귀모델이 데이터에 잘 피팅되는지 test
* 2개의 회귀모델을 가지고( nested관계) 더 좋은 모델을 판별할 때
* 데이터가 주어졌는데, 그 데이터는 이미 정규성가정, 등분산 가정을 만족했을 때, 그 두 집단 간 평균이 동일한지 test => ANOVA가 여기에 해당합니다. 



(3) Formula and calculation (1) - Regression problems

대부분의 f test들은 `decomposition of the variability in a collection of data in terms of SS`로 부터 시작됩니다. 즉, 분산을 sum of squares의 관점으로 분해하는 것입니다. 검정통계량은 따라서 2개의 scaled된 SS의 비율로 나타나지는데, 이 때 2개의 ss는 다른 종류의 분산을 반영하고 있어야 합니다. 이 ss들은 검정통계량이 귀무가설이 거짓일 때 커지는 방향으로 만들어져야합니다. 검정통계량을 이루는 두 개의 ss는 서로 독립이어야 하며( f 분포 정의에 따라 ), 각각은 카이제곱분포를 따릅니다. 각각이 카이제곱분포를 따른다는 것은 데이터값이 서로 독립이며 정규성을 띄고 등분산성을 만족할 때 성립됩니다.

이제, 이러한 사전지식을 바탕으로 회귀분석을 이해해봅시다. 여기에 2가지 모델이 있습니다. M1,M2로 표시하겠습니다. M1은 M2에 nested되어 있습니다. 즉, M1은 reduced model= restricted model=귀무가설 하 모델, M2는 full model= unrestricted model=대립가설 모델 입니다. 따라서 M1이 p1개의 파라메터를 가진다면 M2는 p2개의 파라메터를 가지며, p1<p2입니다. 

보통 데이터에 모델을 피팅할 때, 가장 이상적이면서 먼저 확인하는 모델은 가장 naive한 모델, 즉 intercept-only model입니다. 이 naive 모델은 restricted model인데, 왜냐하면 잠재적으로 추가될 수 있는 파라메터들이 모두 set zero상태이기 때문입니다. 따라서 귀무가설 하의 모델입니다. 

또 다른 common한 상황으로는 데이터에 구조적 결함이 있는지 판단하는 상황입니다. 이 상황에서 restricted model은 모든 데이터를 하나의 회귀모형을 만들기 위해 전부 사용됩니다. 반면, unrestricted model(full model)에서는 데이터를 2개의 다른 subset으로 나누어 각각에 대해 regression model을 피팅합니다. 이것은 chow test라고도 불립니다.

보통, 더 많은 파라메터를 가지고 있는 모형(full model,대립가설)이 restricted model에 비해 더 flexible하며 주어진 데이터를 잘 설명합니다. 따라서, 앞의 모형을 다시 보면 M1보다 M2가 좀더 `lower error, better fit to data`가 되겠습니다. 이를 검증하기 위해 사용되는 방법이 F-test입니다.

만약 n개의 데이터 포인트가 있다고 합시다. 그리고 앞과 같이 2개의 nested된 모델이 있습니다. 그러면 우리는 F검정통계량을 다음과 같이 계산할 수 있습니다.

~~~
F statistic = [(RSS1 - RSS2)/(p2-p1)]/ (Rss2/n-p2)
~~~
RSS1은 M1모델하여서의 SSE를 말합니다.(= SSE(RM))
RSS1의 자유도는 n-(p1+1)입니다.
RSS2은 M2모델하여서의 SSE를 말합니다.(= SSE(FM))
Rss2의 자유도는 n-(p2+1)입니다. 

귀무가설 하( smaller model) F 통계량이 critical value보다 크다면, 분모다 크다는 말이 되겠고, 그렇다면 M1모델 하에서 에러가 M2보다 유의미하게 더 크다는 게 됩니다. (절대 이 값이 음수가 나오지 않습니다. ) 따라서 우리는 이 경우 귀무가설을 기각하게 됩니다. 

위의 f 검정통계량은 귀무가설, 즉 full model이 nested model보다 더 나은 결과를 보여주지 않는다. = M1 모델이 낫다 가 참이라는 가정하에 만들어진 통계량임을 주의합시다. 가설을 기각하는 것은 다른 검정할때와 똑같습니다. 임계값을 구해주고, p value를 계산한 다음, 1종오류보다 p value가 작으면 기각하는 것입니다. 

(4) 아노바에 대해 하기 전에 간단한 설명

F test가 one-way analysis of variance에 쓰이는 경우는 다음을 알아보기 위해서입니다.
~~~
* The expected value(기댓값, 평균)of 양적 변수가 pre-defined groups 마다 다른가?
* A치료법이 다른 B,C,D 치료법보다 더 우수한가?
~~~
위의 경우 귀무가설은 아래와 같이 쓸 수 있습니다.
 **귀무가설: A,B,C,D 치료법은 차이가 없다.**

아노바의 장점은 나중에 더 얘기하기로 하고, 일단 가장 크게 두드러진 장점은 비교대상이 여러개일때, pairwise로 전부 짝지어 비교할 필요가 없다는 것입니다. 훨씬 수월하고, 시간도 절약할 수 있습니다. 그러나 단점으로는 만약 귀무가설이 기각되고, 4집단 간에 차이가 있다고 판단했을 때, 어떤 그룹 간 차이가 있는지는 추가적으로 셰피나 투키 테스트를 해야지만 알 수 있습니다. 

## 3. regression and test

regression model 자체도 매우 큰 의미를 가지지만, 통계학에서 더욱 집중하는 부분은 regression models 중 가장 best를 찾는 일입니다. 이러한 과정은 대부분 가설검정을 통해서 이루어집니다. 크게 학부에서는 t test와 f test 2가지를 가지고 더 나은 회귀모델을 찾습니다. 이를 어떻게 하는지, 알아봅시다!

(1) regression table

[rotation]
```
n= number of data points
p= number of parameters( include intercept term)
```
**p의 정의는 전공서적마다 정말 천차만별입니다. 심지어 제 전공수업에서도 가끔 로테이션을 교수님이 다르게 설명하셔서 정말 이해하는데.. 어려웠습니다. 저는 이제부터 p를 intercept term을 포함한 모든 모수의 갯수라고 정의하겠습니다.**

* uncorrected Sum of Squares(ss)

| source | d.f |
|--------|--------|
|  Null(n*E(Y)^2)  |    1  |
|  SSR(trt)  |   p-1   |
|  SSE(within)  |   n-p   |
|  SST  |n|


* corrected ss

| source | d.f |
|--------|--------|
|  SSR(trt) |   p-1   |
|  SSE(within) |   n-p   |
|  SST  |   n-1   |

~~~
[참고]
이 부분은 제가 이해하기 좀 어려웠던 부분이라 특별히 강조해서 정리하겠습니다. 다음 식은 F 통계량을 구하는 식입니다.

F=MSR/MSE = (SSR(RM)/p-1)/(SSE(FM)/n-p-1) 

회귀해석에서 f test를 찾아보면 위와 같은 식이 매우 많이 보일 것입니다. 그런데 이를 어떻게 해석해야할까요?

먼저 앞에 MSR/MSE 이렇게 정의된 부분은 너무 간략하게 되어있는 것 같네요.  실제로는 MSR(FM)/MSE(FM) 이렇게 되어있어야 합니다. 

그런데, 이렇게 f 통계량을 구하는 것은 변수의 수와 FM과 RM 간 변수 갯수의 차이가 같을 때만 적용할 수 있습니다. 즉, FM은 상관없지만, RM은 항상 intercept only model일 때만 적용되는 검정통계량 공식입니다.  그렇다면 좀 더 일반화되어 적어봅시다.

F= {[(SSE(RM)-SSE(FM)]/[df(sse_rm)-df(sse_rm)]} /  {(SSE(FM)/n-p) }

이게 제대로 된 검정통계량 식입니다. df(sse_rm)-df(sse_rm) 이 부분을 다시 정리해보면 두 모델 간 변수 갯수의 차이가 됩니다. 즉 FM이 RM보다 변수를 몇개 더 가졌는지의 갯수가 자유도로 들어가게 됩니다.

중요한 것은 F통계량이 임계값보다 크면 귀무가설을 기각하고 Full model이 better model이라고 결정하게 되는데 그 이유가 무엇일까요? 결정적 근거는 SST가 두 모델 모두에 대해서 같은 양을 가지고 있기 때문입니다. 

이를 이용하면,  (SSE(RM)-SSE(FM) 이부분은 RM이 설명하지 못하는 error부분을 FM이 설명하는 양이 됩니다. 따라서 결국 가설검정의 목표는  RM이 설명하지 못하는 error부분을 FM이 설명하는 양은 절대 음수가 나올 수 없고 양의 값이 나올 텐데, 

이 값이 정말로 RM을 기각하고 FM을 사용할만큼 의미가 있는 값인지를 test하자는 것입니다. 왜냐하면 RM은 FM보다 단순하고 해석도 쉽기 때문에, 유의미하게 에러를 더 설명해주지 않는다면, RM을 사용하는 것이 여러모로 효율적이기 때문입니다. 

~~~


## 4. Anova

(1) classes of models

아노바 모형은 크게 3가지로 나뉠 수 있습니다.

* Fixed-effects models 

 	fixed-effects model of ANOVA 모형은 다음과 같은 상황에 적용되는 모델입니다. 실험자가 하나나 그 이상의 treatments를 subjects에게 적용하고, 실험자는 response variable(ex. 질병에 걸릴 확률..)이 treatment마다 다른지 관찰합니다. 

* Random-effects models

    random-effects model of ANOVA 모형은 treatments가 고정되어있지 않을 경우 사용합니다. 이러한 상황은 다양한 factor levels가 큰 모집단에서 추출된 경우입니다. 

* Mixed-effects models

    mixed-effects models of ANOVA 모형은 앞서 말한 두가지의 effect types를 모두 가지고 있습니다. 예를 들면, 대학교에서 좋은 전공입문서를 찾기위한 실험을 수행한다고 합시다. 이 때, 각 전공입문서 종류는 treatments에 해당합니다. fixed-effects model은 전공입문서의 리스트후보를 비교합니다. random-effects model은 랜덤하게 선택된 전공입문서 간 차이가 존재하는지 검증합니다. mixed-effects model은 기존 고정된 전공입문서를 무작위로 선택된 대안인 전공입문서와 비교합니다. 
    
cf. one-way anova와 two-way anova 차이

전자와 후자를 구분하는 것은 학부생으로서 계속 공부하면서 너무너무너무 해갈렸었습니다.. 사실 지금은 확실히 구분할 수 있지만 이렇게 된것은 자주 보는 것밖에 답이 없다는 것.. 그래서 다시한번 적어놓고 가려 합니다.

<구분기준>


~~~

독립변수가 1개면 전자, 2개 이상이면 후자
ex) 대학교 1,2,3학년 학생들의 토익성적의 평균을 비교 - oneway
ex) 대학교 1,2,3학년 학생들을 대상으로 A,B,C사의 커피를 각각 먹였을 때, 2시 수업에서 피로를 느끼는 정도의 차이를 비교 - two way
~~~

(2) CAD

 총 5개의 temperature group이 있고, 각 그룹마다 온도가 F로 나타나져있는 데이터를 가지고 아노바 분석을 해보겠습니다. 코드는 R 코드를 참고로 합니다. ( 동국대학교 박주현 교수님의 CAD lecture의 코드를 참고하였습니다.) 지금은 one-way anova입니다.


* 데이터 불러오기

~~~
resin <- read.table("exmpl3.2", header=TRUE)
str(resin) # temp=1.2.3.4.5  => 그룹 인덱스 
temp <- as.factor(resin$temp) 
#  temp변수를 factor로 바꿔줌
resin<-within(resin,{temp <- as.factor(temp)})
summary(resin) 
~~~

* 데이터 구조 확인

	* sapply(vector_or_list, apply_function) : returns list of same length of first argument. each elements are applied by function.

	* with(dataset_name,apply_function): 매번 dataset$variable_name 하기 귀찮아서.


	* split(나누고 싶은 데이터가 들어있는 vector(factor), 나누는 기준으로 사용되는 vector(factor)) : returns lists. 

~~~
# 각 5개의 temp에 대한 summary를 보여준다.
sapply(with(resin, split(y, temp)), summary)  
sapply(with(resin, split(y, temp)), length)   
boxplot(y~temp, data=resin)

# 각 5개의 그룹별로 기온평균에 대한 boxplot을 그렸을 때 linear하게 decreasing하는 경향을 볼 수 있습니다. 먼저 생각나는 모형은 lm()이죵

~~~

* 회귀선 적합
~~~
lm1=lm(y~temp,data=resin)
summary(lm1)
~~~

결과는 아래와 같습니다. 

~~~

Call:
lm(formula = y ~ temp, data = resin)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.22667 -0.03667  0.00250  0.03125  0.20333 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.93250    0.03387  57.055  < 2e-16 ***
temp194     -0.30375    0.04790  -6.341 4.06e-07 ***
temp213     -0.55500    0.04790 -11.586 5.49e-13 ***
temp231     -0.73821    0.04958 -14.889 6.13e-16 ***
temp250     -0.87583    0.05174 -16.928  < 2e-16 ***

Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.0958 on 32 degrees of freedom
Multiple R-squared:  0.9233,    Adjusted R-squared:  0.9138 
F-statistic: 96.36 on 4 and 32 DF,  p-value: < 2.2e-16

~~~

 결과를 해석해봅시다. 여기서 coefficients에 temp175가 없죠? 지금 temp175가 기준으로 reference coding 되어있어서 그렇습니다. 그리고 나머지 4개의 변수들도 모두 factor형이기 때문에, 각 변수들에 대한 coefficients들은 temp175(beta0)그룹의 평균과의 차이를 뜻하게 됩니다. 그리고 모든 변수가 유의하게 나왔으니 이 resin데이터는 linear텀을 가지고 있다고 판단할 수 있습니다. 
 잘 이해가 안되면, 다음 코드를 통해 다시한번 확인해봅시다.

 cf. tappy(y,temp,mean)는 y를 temp란 팩터변수를 기준으로 mean을 계산하는 함수입니다.

 ~~~
 with(resin,tapply(y,temp,mean))
 coef(lm1)
 ~~~
 * 결과

```
  with(resin,tapply(y,temp,mean))
     175      194      213      231      250 
1.932500 1.628750 1.377500 1.194286 1.056667 

 coef(lm1) 
(Intercept)     temp194     temp213     temp231     temp250 
  1.9325000  -0.3037500  -0.5550000  -0.7382143  -0.8758333 

```

 결과를 보시면, intercept텀은 평균과 계수가 동일함을 알수있습니다. 그렇다면 위 평균값을 빼봅시다. temp194-temp175= -.3037이 나오고, 이는 회귀선에서 temp194의 계수값과 일치합니다.

 * fitting된 회귀model을 가지고 anova table 만들기

```
 anova(lm1)
 Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value    Pr(>F)
temp       4 3.5376 0.88441  96.363 < 2.2e-16 ***
Residuals 32 0.2937 0.00918

```


 다음 결과를 보면 temp는 위에서 말한 SSR(SS_model)부분이고, residual은 SSE부분임을 알 수 있습니다. 자유도를 계산해보면, N=37, p=모수의 갯수=5, 변수의 갯수=4임을 이용합니다. SSR의 자유도는 변수의 갯수이므로 4이고, SSE의 자유도는 N-모수의수를 해준 32가 나옵니다. 위 아노바에서 귀무가설은 5그룹간의 온도평균은 동일하다 입니다. 그런데 pvalue가 매우 작으며 유의하다고 나왔습니다. 그렇다면 우리는 귀무가설을 기각할 수 있으며 따라서 대립가설인 5그룹 간 온도평균은 동일하지 않다라고 결론내릴 수 있겠습니다.

 앞선 코드에서는 temp변수를 factor로 지정했습니다. 만약 이 변수가 그냥 numeric이라면 어떻게 피팅이 되고 해석일 될까요?



 ~~~
 resin$temp2<-resin$temp # new variable 
# levels(x)<-value : x는 object. 먼저 factor로 변경
levels(resin$temp2)<-c(175, 194, 213, 231, 250) 
# factor변수를 numeric으로 변경
resin$temp2<-as.numeric(levels(resin$temp2))[resin$temp2] 
with(resin,tapply(temp2,temp,summary))

 ~~~

새롭게 만든 numeric변수 temp2를 가지고 polynomial를 피팅해봅시다.

* polynomial regression model fitting

```
lm2<-lm(y~temp2+I(temp2^2)+I(temp2^3)+I(temp2^4), data=resin)
summary(lm2)
summary(aov(y~temp2+I(temp2^2)+I(temp2^3)+I(temp2^4), data=resin)) 
summary(aov(y~I(temp2^2)+I(temp2^3)+I(temp2^4), data=resin)) 
```
결과를 보면 summary(lm2)에선 모든 계수가 유의하지 않다고 나오네요
일단 temp2 term이 유의한지 anova모형을 피팅해주는 aov함수를 써서 비교해보겠습니다.

```
summary(aov(y~temp2+I(temp2^2)+I(temp2^3)+I(temp2^4), data=resin)) 
summary(aov(y~I(temp2^2)+I(temp2^3)+I(temp2^4), data=resin))
```

결과를 보면 첫번째 summary, 즉 temp2가 들어간 lm모형을 통해 아노바모형을 만들었을 때, 우리는 temp2 텀과 그 제곱텀이 유의함을 알 수 있습니다. 그 말은, 폴리노미얼 모델에 대해 조금 더 설명해야지 이해할 수 있습니다. 폴리노미얼 모델은 평균을 여러개의 회귀모델의 sum으로 만든 모델을 말합니다. 다시말해, 위의 결과로 해석하자면 이 resin데이터에 맞는 폴리노미얼 회귀식은 linear,qudartic의 모델을 가지고 있다는 것이고, 이 모델들이 SSM을 구성하게 되는 것입니다. 따라서 각 모델의 계수는 해당 모델이 평균에 미치는 영향도를 수치화 한 값이 될 것입니다.

```
Anova(lm2, type='3')
```

위 함수는 앞이 anova와 다릅니다. 소문자 anova는 그냥 해당 회귀식에 대한 아노바table을 만들어주는 것입니다. 아래 링크를 읽어보시면 도움이 될 것입니다. 
[Anova()에 대한 설명들](https://www.r-bloggers.com/anova-%E2%80%93-type-iiiiii-ss-explained/) 

Anova함수는 여러개의 모델에 대한 테이블을 만들어줍니다. 이 때 arguments는 Anova(lm,type)으로 지정하게 됩니다. type에 대해 조금 더 설명하겠습니다. types1,2,3이 있는데 type이란 데이터가 unbalanced할 때, 아노바의 Sum of suqres를 계산하는 다른 방법들을 말합니다. 어떤 타입을 쓸건지는 항상 논쟁이 이어지고있습니다. 

* type 1: sequential sum of squares

	 어떤 모델이 있는데, factors A,B 2개를 포함한다고 합시다. 여기에는 따라서 A,B,A:B(interaction) 3가지의 효과가 있습니다. full model을 SS(A,B,AB)로 표현하겠습니다. 각 특정한 factor의 효과를 보기 위해서 우리는 보통 다른 모델들을 추가적으로 만들어 test합니다. 예를 들어, AB 텀이 유효한지 아닌지 검증하기 위해서 F test를 하는데, 이때 SS(A,B)와 SS(A,B,AB) 두 모델을 비교합니다.                      type 1을 sequential increase라 하는 이유는 맨 처음에는 A만 넣어서 Sum of squares를 계산합니다. 그리고 B를 추가적으로 넣어 SS(B given A)를 계산하고, 그다음 AB를 넣어 SS(AB given A and B)를 계산합니다. 추가되고 추가되어 조건부확률과 같은 모양을 띄므로, 처음에 main effect를 무엇을 정하느냐에 따라 SS값도 달라집니다. 따라서 unbalance data가 있을 땐 이 타입을 그렇게 선호하지 않습니다.

* type 2: SS(A|B), SS(B|A)를 계산합니다. 즉, 각각 메인 효과에 대한 Sum of squares를 계산합니다. interaction term은 계산하지 않습니다. 다시말해, SS(AB|A,B)를 먼저 계산하고, AB텀이 유효하지 않다면 이제 이 타입을 써서 각각 메인 효과에 대한 것을 계산하는 것입니다. 이 타입은 함수 anova(lm_model) 을 했을 때 그 모델의 ss를 측정하는데 쓰입니다. ``만약 interaction term이 없다면 type2가 type3보다 더 power가 큽니다.``

* type3: 다음 2가지 SS를 계산합니다.

SS(A | B, AB) for factor A
SS(B | A, AB) for factor B

이 타입은 메인효과 A,B의 유의성을 다른 하나의 메인효과와 interaction term이 주어졌을 때의 조건 하에서 계산합니다. 따라서 이 타입은 interaction term이 유효할 때 주로 사용됩니다. 그러나 보통 interaction term이 유효하면 그 텀을 구성하는 각각의 메인효과는 딱히 크게 신경쓰지 않습니다. 

[NOTE] 만약 데이터가 balanced하다면, factors는 orthogonal이 될 것이고, 따라서 type 1,2,3 모두 같은 결과를 낼 것입니다. 

요약하자면, 우리가 가설검정 하는 주된 목적은 각 factor의 유효성을 알기 위해서인데, 그 유효성을 알고싶은 한 팩터에 대해서 다른 팩터들을 고정시킨 후 측정하게 됩니다. 보통, 인터렉션 효과가 없다면 type2가 가장 powerful합니다. 그러나 있다면, type3가 낫습니다. 


* poly함수에 대한 간략한 소개

 ==poly(x,degree of polynomial)==

 poly함수는 orthogonal polynomials를 계산하는 함수입니다. x는 메트릭스나 벡터이고, NA값을 허용하지 않습니다. numeric형이어야 합니다. x는 evaluate the polynomial할 때 쓰입니다.
 resin 데이터에서는 그룹이 5개 있으므로 모델은 4개가 만들어질 수 있겠죠. 따라서 degree=4가 됩니다.


* poly함수를 이용해 4개의 orthogonal polynomial생성

```
temp.poly4<-poly(resin$temp2, 4) # 37 by 4 matrix
resin[,4:7]<-temp.poly4 # 4개 column add 
names(resin)[4:7]<-paste("poly", 1:4, sep="")
str(resin)

```


* orthogonal polynomial

```
# poly로 polynomial regression model 만든다.
lm3<-lm(y~poly1+poly2+poly3+poly4, data=resin)		
summary(lm3) # poly1,2유의함 
 anova(lm3) 
 anova(lm2) # same! 
 # lm2:lm2<-lm(y~temp2+I(temp2^2)+I(temp2^3)+I(temp2^4), data=resin) ;; 즉 temp2가 factor형이 아닌 numeric형일때의 polynomial.
```

* 결과 해석

```
summary(aov(y~poly1+poly2+poly3+poly4, data=resin)) 
Anova(lm3, type='3') 
```

